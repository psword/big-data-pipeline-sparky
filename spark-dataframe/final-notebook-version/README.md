# ğŸ“” final-notebook-version  
**Instructions below ğŸ‘‡**

---
This is the final copy! ğŸ¥‡

ğŸ’» Uses Google Colab for interactive coding

ğŸƒ Connects to MongoDB Atlas to store TMDB movie data

âš¡ Processes data with Apache Spark

ğŸ“Š Includes Dataview exploration for visual summaries

Cloud tools and big data can working together on a movie dataset ğŸ¬

---

## ğŸ‘‰ To run this notebook:

*Prerequisites*
- This notebook uses a cloud connection to MongoDB Atlas. The connection credentials
  must be in the notebook and the dataset must be live in order to use **this** example.

- It is built for the Colab environment. For one-click import and execute, you must
  have a Google account with a Colab workspace.

*Otherwise*
- The ![image](https://github.com/user-attachments/assets/3ea68c26-52d5-4e57-ab57-c71319915fcd) button (not this one...but the one in the notebook)
  is up-to-date and has been tested for 1-click import directly into Colab.  
- If 1-click does not work for some reason, download the notebook, and import it into Colab.
- Next:  
  â—Obtain a copy of the dataset from Kaggle (see the [DATASET_LICENSE](DATASET_LICENSE)), set it up in MongoDB ATLAS,
      and adapt the connection string for your own scenario in the Notebook.  
  *  
  OR  
  *  
  â—Obtain a copy of the dataset in CSV form, upload the file to Colab, and adapt the Spark session for that scenario for testing.  
    - ğŸ“„ You will find an adaptation for that case in the [colab-testing](spark-dataframe/google-colab-testing/colab-testing.py) folder.
  
  ğŸ§ª Happy Data-ing!
