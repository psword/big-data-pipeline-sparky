# 📔 final-notebook-version  
**Instructions below 👇**

---
This is the final copy! 🥇

💻 Uses Google Colab for interactive coding

🍃 Connects to MongoDB Atlas to store TMDB movie data

⚡ Processes data with Apache Spark

📊 Includes Dataview exploration for visual summaries

Cloud tools and big data can working together on a movie dataset 🎬

---

## 👉 To run this notebook:

*Prerequisites*
- This notebook uses a cloud connection to MongoDB Atlas. The connection credentials
  must be in the notebook and the dataset must be live in order to use **this** example.

- It is built for the Colab environment. For one-click import and execute, you must
  have a Google account with a Colab workspace.

*Otherwise*
- The ![image](https://github.com/user-attachments/assets/3ea68c26-52d5-4e57-ab57-c71319915fcd) button (not this one...but the one in the notebook)
  is up-to-date and has been tested for 1-click import directly into Colab.  
- If 1-click does not work for some reason, download the notebook, and import it into Colab.
- Next:  
  ❗Obtain a copy of the dataset from Kaggle (see the [DATASET_LICENSE](DATASET_LICENSE)), set it up in MongoDB ATLAS,
      and adapt the connection string for your own scenario in the Notebook.  
  *  
  OR  
  *  
  ❗Obtain a copy of the dataset in CSV form, upload the file to Colab, and adapt the Spark session for that scenario for testing.  
    - 📄 You will find an adaptation for that case in the [colab-testing](spark-dataframe/google-colab-testing/colab-testing.py) folder.
  
  🧪 Happy Data-ing!
